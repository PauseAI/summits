# Draft: EA Forum Post

**Title**: Building a shared database of government AI policy contacts - seeking collaborators

**Tags**: AI governance, AI safety, coordination, infrastructure, PauseAI

---

## The problem

Civil society organizations working on AI governance face a common challenge: identifying the right contacts in each country's AI policy apparatus. When preparing for international summits (Bletchley → Seoul → Paris → India 2026), we need to know:

- Which ministry handles AI policy in Country X?
- Who are the key officials and their contact details?
- Did this country sign the Bletchley/Seoul/Paris declarations?
- Do they have a national AI Safety Institute?

**This information exists, scattered across government websites, press releases, and individual organization's contact lists. But no shared resource exists.**

I asked about this on the AI Safety Communications Discord in December 2024 and got silence. Established organizations (CLTR, FLI, GovAI) have their own contacts but don't share them—their access depends on relationships they've cultivated individually.

## What I'm building

I've started a systematic effort to compile this information for all GPAI member states (44 countries) plus other summit participants. The repository is at [GitHub link].

Current state:
- Framework designed (JSON data structure, research methodology)
- ~1 country completed (UK)
- ~49 countries to go

## Why share this?

1. **Avoids duplication**: Multiple orgs researching the same ministry websites is wasteful
2. **Lowers barrier**: Smaller organizations can't afford this research time
3. **Enables coordination**: Knowing who's engaging with which country prevents stepping on toes
4. **Creates accountability**: Public resource means errors get caught and fixed

## What I'm looking for

**Research contributors**: If you have 2-4 hours and internet access, you can research 2-3 countries following the methodology. PRs welcome.

**Existing contact lists**: If your organization has partial lists you'd share (even just "these 10 countries we've verified"), we can integrate them.

**Corrections**: If you spot errors in countries already completed, please flag them.

**Strategic input**: Should this be PauseAI-branded or coalition-owned? What license?

## Why me / PauseAI?

I'm Anthony Bailey, volunteer Software Lead for PauseAI. Previously 17 years at Amazon as Senior SDE. Left in 2024 to work on AI safety advocacy full-time.

PauseAI is a logical home because:
- We're explicitly focused on international coordination / treaty approaches
- We're not competing with CLTR/FLI for the same policy access
- We have no incentive to hoard contacts
- We're already planning India Summit engagement

But I'm genuinely open to this being a broader coalition resource if that increases adoption.

## How to contribute

1. Clone the repo: [GitHub link]
2. Pick a country from PROGRESS.md
3. Follow METHODOLOGY.md
4. Submit a PR

Or just DM me if you have partial information to share.

---

## Notes for posting

- Post to EA Forum, consider cross-posting to LessWrong
- Share in AI Safety Communications Discord (where the original silence came from)
- Maybe contact CLTR/FLI directly to ask if they'd contribute
- Time posting for weekday visibility
